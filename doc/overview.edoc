%%==============================================================================
%% Copyright 2014 Ulf Wiger
%%
%% Licensed under the Apache License, Version 2.0 (the "License");
%% you may not use this file except in compliance with the License.
%% You may obtain a copy of the License at
%%
%% http://www.apache.org/licenses/LICENSE-2.0
%%
%% Unless required by applicable law or agreed to in writing, software
%% distributed under the License is distributed on an "AS IS" BASIS,
%% WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
%% See the License for the specific language governing permissions and
%% limitations under the License.
%%==============================================================================

@copyright 2014-2018 Ulf Wiger
@version 0.9.0
@title jobs - a Job scheduler for load regulation

@doc

[![Build Status](https://github.com/uwiger/jobs/actions/workflows/ci.yml/badge.svg?branch=master)](https://github.com/uwiger/jobs/actions/workflows/ci.yml)

JOBS
====

Jobs is a job scheduler for load regulation of Erlang applications.
It provides a queueing framework where each queue can be configured
for throughput rate, credit pool and feedback compensation.
Queues can be added and modified at runtime, and customizable
"samplers" propagate load status across all nodes in the system.

Specifically, jobs provides three features:

* Job scheduling: A job is scheduled according to certain constraints.
  For instance, you may want to define that no more than 9 jobs of a
  certain type can execute simultaneously and the maximal rate at
  which you can start such jobs are 300 per second.
* Job queueing: When load is higher than the scheduling limits
  additional jobs are *queued* by the system to be run later when load
  clears. Certain rules govern queues: are they dequeued in FIFO or
  LIFO order? How many jobs can the queue take before it is full? Is
  there a deadline after which jobs should be rejected. When we hit
  the queue limits we reject the job. This provides a feedback
  mechanism on the client of the queue so you can take action.
* Sampling and dampening: Periodic samples of the Erlang VM can
  provide information about the health of the system in general. If we
  have high CPU load or high memory usage, we apply dampening to the
  scheduling rules: we may lower the concurrency count or the rate at
  which we execute jobs. When the health problem clears, we remove the
  dampener and run at full speed again.

Error recovery
--------------

The Jobs server is designed to not crash. However, in the unlikely event
that it should occur (and it has!) Jobs does not automatically restore changes
that have been effected through the API. This can be enabled, setting the
Jobs environment variable `auto_restore' to `true', or calling the function
`jobs_server:auto_restore(true)'. This will tell the jobs_server to remember
every configuration change and replay them, in order, after a process restart.

Examples
--------

The following examples are fetched from the EUC 2013 presentation on Jobs.

<h4>Regulate incoming HTTP requests (e.g. JSON-RPC)</h4>

<pre lang="erlang">
%% @doc Handle a JSON-RPC request.
handler_session(Arg) -&gt;
    jobs:run(
        rpc_from_web,
        fun() -&gt;
               try
                  yaws_rpc:handler_session(
                    maybe_multipart(Arg),{?MODULE, web_rpc})
               catch
                   error:E -&gt;
                       ...
               end
    end).
</pre>

<h4>From Riak prototype, using explicit ask/done</h4>

<pre lang="erlang">
case jobs:ask(riak_kv_fsm) of
  {ok, JobId} -&gt;
    try
      {ok, Pid} = riak_kv_get_fsm_sup:start_get_fsm(...),
      Timeout = recv_timeout(Options),
      wait_for_reqid(ReqId, Timeout)
    after
      jobs:done(JobId)  %% Only needed if process stays alive
    end;
  {error, rejected} -&gt;  %% Overload!
    {error, timeout}
end
</pre>

<h4>Shell demo - simple rate-limited queue</h4>

<pre lang="erlang">
2&gt; jobs:add_queue(q, [{standard_rate,1}]).
ok
3&gt; jobs:run(q, fun() -&gt; io:fwrite("job: ~p~n", [time()]) end).
job: {14,37,7}
ok
4&gt; jobs:run(q, fun() -&gt; io:fwrite("job: ~p~n", [time()]) end).
job: {14,37,8}
ok
...
5&gt; jobs:run(q, fun() -&gt; io:fwrite("job: ~p~n", [time()]) end).
job: {14,37,10}
ok
6&gt; jobs:run(q, fun() -&gt; io:fwrite("job: ~p~n", [time()]) end).
job: {14,37,11}
ok
</pre>

<h4>Shell demo - "stateful" queues</h4>

<pre lang="erlang">
Eshell V5.9.2 (abort with ^G)
1&gt; application:start(jobs).
ok
2&gt; jobs:add_queue(q,
     [{standard_rate,1},
      {stateful,fun(init,_) -&gt; {0,5};
                   ({call,{size,Sz},_,_},_) -&gt; {reply,ok,{0,Sz}};
                   ({N,Sz},_) -&gt; {N, {(N+1) rem Sz,Sz}}
                end}]).
ok
3&gt; jobs:run(q,fun(Opaque) -&gt; jobs:job_info(Opaque) end).
0
4&gt; jobs:run(q,fun(Opaque) -&gt; jobs:job_info(Opaque) end).
1
5&gt; jobs:run(q,fun(Opaque) -&gt; jobs:job_info(Opaque) end).
2
6&gt; jobs:run(q,fun(Opaque) -&gt; jobs:job_info(Opaque) end).
3
7&gt; jobs:run(q,fun(Opaque) -&gt; jobs:job_info(Opaque) end).
4
8&gt; jobs:run(q,fun(Opaque) -&gt; jobs:job_info(Opaque) end).
0
9&gt; jobs:run(q,fun(Opaque) -&gt; jobs:job_info(Opaque) end).
1
%% Resize the 'pool'
10&gt; jobs:ask_queue(q, {size,3}).
ok
11&gt; jobs:run(q,fun(Opaque) -&gt; jobs:job_info(Opaque) end).
0
12&gt; jobs:run(q,fun(Opaque) -&gt; jobs:job_info(Opaque) end).
1
13&gt; jobs:run(q,fun(Opaque) -&gt; jobs:job_info(Opaque) end).
2
14&gt; jobs:run(q,fun(Opaque) -&gt; jobs:job_info(Opaque) end).
0
...
</pre>

<h4>Demo - producers</h4>

<pre lang="erlang">
Eshell V5.9.2 (abort with ^G)
1&gt; application:start(jobs).
ok
2&gt; jobs:add_queue(p,
  [{producer, fun() -&gt; io:fwrite("job: ~p~n",[time()]) end},
   {standard_rate,1}]).
job: {14,33,51}
ok
3&gt; job: {14,33,52}
job: {14,33,53}
job: {14,33,54}
job: {14,33,55}
...
</pre>

<h4>Demo - passive queues</h4>

<pre lang="erlang">
2&gt; jobs:add_queue(q,[passive]).
ok
3&gt; Fun = fun() -&gt; io:fwrite("~p starting...~n",[self()]),
3&gt;                Res = jobs:dequeue(q, 3),
3&gt;                io:fwrite("Res = ~p~n", [Res])
3&gt;       end.
#Fun&lt;erl_eval.20.82930912&gt;
4&gt; jobs:add_queue(p, [{standard_counter,3},{producer,Fun}]).
&lt;0.47.0&gt; starting...
&lt;0.48.0&gt; starting...
&lt;0.49.0&gt; starting...
ok
5&gt; jobs:enqueue(q, job1).
Res = [{113214444910647,job1}]
ok
&lt;0.54.0&gt; starting...
</pre>

<h4>Demo - queue status</h4>

<pre lang="erlang">
(a@uwair)1&gt; jobs:queue_info(q).
{queue,[{name,q},
        {mod,jobs_queue},
        {type,fifo},
        {group,undefined},
        {regulators,[{rr,[{name,{rate,q,1}},
                          {rate,{rate,[{limit,1},
                          {preset_limit,1},
                          {interval,1.0e3},
                          {modifiers,
                           [{cpu,10},{memory,10}]},
                          {active_modifiers,[]}
                         ]}}]}]},
        {max_time,undefined},
        {max_size,undefined},
        {latest_dispatch,113216378663298},
        {approved,4},
        {queued,0},
        ...,
        {stateful,undefined},
        {st,{st,45079}}]}
</pre>

<hr/>

##Scenarios and Corresponding Configuration Examples

####EXAMPLE 1:
* Add counter regulated queue called <b><i>heavy_crunches</i></b> to limit your cpu intensive code executions to no more than 7 at a time

Configuration:
<pre lang="erlang">
{ jobs, [
    { queues, [
        { heavy_crunches, [ { regulators, [{ counter, [{ limit, 7 }] } ] }] }
      ]
    }
  ]
}
</pre>

Anywhere in your code wrap cpu-intensive work in a call to jobs server and-- <b>voil√†!</b> --it is counter-regulated:

<pre lang="erlang">
jobs:run( heavy_crunches,fun()->my_cpu_intensive_calculation() end)
</pre>

####EXAMPLE 2:
* Add rate regulated queue called <b><i>http_requests</i></b> to ensure that your http server gets no more than 1000 requests per second.
* Additionally, set the queue size to 10,000 (i.e. to control queue memory consumption)

Configuration:

<pre lang="erlang">
{ jobs, [
      { queues, [
            { http_requests, [ { max_size, 10000},  {regulators, [{ rate, [{limit, 1000}]}]}]}
        ]
      }
  ]
}
</pre>

Wrap your request entry point in a call to jobs server and it will end up being rate-regulated.

<pre lang="erlang">
jobs:run(http_requests,fun()->handle_http_request() end)
</pre>

NOTE: with the config above, once 10,000 requests accumulates in the queue any incoming requests are dropped on the floor.

####EXAMPLE 3:
* HTTP requests will always have a reasonable execution time.  No point in keeping them in the queue past the timeout.

* Let's create <b><i>patient_user_requests</i></b> queue that will keep requests in the queue for up to 10 seconds

<pre lang="erlang">
{ patient_user_requests, [
    { max_time, 10000},
    { regulators, [{rate, [ { limit, 1000 } ] }
  ]
}
</pre>
* Let's create <b><i>impatient_user_requests</i></b> queue that will keep requests in the queue for up to 200 milliseconds.
Additionally, we'll make it a LIFO queue. Unfair, but if we assume that happy/unhappy is a boolean
we're likely to maximize the happy users!



<pre lang="erlang">
{ impatient_user_requests, [
    { max_time, 200},
    { type, lifo},
    { regulators, [{rate, [ { limit, 1000 } ] }
  ]
}
</pre>

NOTE: In order to pace requests from both queues at 1000 per second, use <b>group_rate</b> regulation (EXAMPLE 4)


####EXAMPLE 4:
* Rate regulate http requests from multiple queues

Create <b>group_rates</b> regulator called <b><i>http_request_rate</i></b>  and assign it to both <i>impatient_user_requests</i> and <i>patient_user_requests</i>

<pre lang="erlang">
{ jobs, [
    { group_rates,[{ http_request_rate, [{limit,1000}] }] },
    { queues, [
        { impatient_user_requests,
            [ {max_time, 200},
              {type, lifo},
              {regulators,[{ group_rate, http_request_rate}]}
            ]
        },
        { patient_user_requests,
            [ {max_time, 10000},
              {regulators,[{ group_rate, http_request_rate}
            ]
        }
      ]
    }
  ]
}
</pre>

####EXAMPLE 5:
* Can't afford to drop http requests on the floor once max_size is reached?
* Implement and use your own queue to persist those unfortunate http requests and serve them eventually


<pre lang="erlang">
 -module(my_persistent_queue).
 -behaviour(jobs_queue).
 -export([  new/2,
            delete/1,
            in/3,
            out/2,
            peek/1,
            info/2,
            all/1]).

 ## implementation
 ...
</pre>

Configuration:

<pre lang="erlang">
{ jobs, [
    { queues, [
        { http_requests, [
            { mod, my_persistent_queue},
            { max_size, 10000 },
            { regulators, [ { rate, [ { limit, 1000 } ] } ] }
          ]
        }
      ]
    }
  ]
}
</pre>


###The use of sampler framework
1. Get a sampler running and sending feedback to the jobs server.
2. Apply its feedback to a regulator limit.

####EXAMPLE 6:
* Adjust rate regulator limit on the fly based on the feedback from <b>jobs_sampler_cpu</b> named <b><i>cpu_feedback</i></b>

<pre lang="erlang">
{ jobs, [
    { samplers, [{ cpu_feedback, jobs_sampler_cpu, [] } ] },
    { queues, [
        { http_requests, [
            { regulators,   [ { rate, [ { limit,1000 } ]  },
            { modifiers,    [ { cpu_feedback,  10} ] } %% 10 = % increment by which to modify the limit
          ]
        }
      ]
    }
  ]
}
</pre>


Prerequisites
-------------
This application requires 'exprecs'.
The 'exprecs' module is part of http://github.com/uwiger/parse_trans

Contribute
----------
For issues, comments or feedback please [create an issue!] [1]

[1]: http://github.com/uwiger/jobs/issues "jobs issues"

@end
